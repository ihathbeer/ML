# Question 1 HW3
# Author: Andrew Nedea

# 4 classes with uniform priors, Gaussian pdfs
import numpy as np
from numpy.linalg import eig
from scipy.stats import multivariate_normal
import matplotlib.pyplot as plt
import random

# Eigenvalues of covariance matrices should be in range [0.5, 1.4]
cov_eigen_bound = [0.5, 1.4]

# Set sizes
train_set_sizes = [100, 200, 500, 1000, 2000, 5000]
test_set_sizes = [100000]

# Class parameters
classes = {
        1: { 
            "mean": [1, 1, 1],
            "cov": [[ 0.8, 0.03, 0.02 ],
                    [ 0.03, 1.12, 0.03],
                    [ 0.02, 0.03, 1.06]],
            "color": "green"
        },
        2: { 
            "mean": [1, -1, 1],
            "cov": [[ 0.92, 0.01, 0.09 ],
                    [ 0.01, 1.32, 0.03],
                    [ 0.09, 0.03, 0.66]],
            "color": "red"
        },
        3: { 
            "mean": [-1, -1, 1],
            "cov": [[ 1.12, 0.02, 0.19 ],
                    [ 0.02, 1.11, 0.03],
                    [ 0.19, 0.03, 0.71]],
            "color": "blue"
        },
        4: { 
            "mean": [-1, 1, -1],
            "cov": [[ 1.02, 0.03, 0.24 ],
                    [ 0.03, 0.97, 0.2 ],
                    [ 0.24, 0.2, 0.82]],
            "color": "purple"
        },
};

def generate_and_sample(sample_no) -> dict:
    """
    Generates distributions and samples for each class and returns a dictionary 
    that maps class labels to a child dictionary. The child dictionary contains 
    two keys (samples and dist). The "samples" key maps to the vector of samples
    X for that class and the "dist" key maps to the multivariate_normal object for
    the class.

    i.e.
    {
        1: {"samples": [[12, 34, 42], ... [123, 2, 3]], "dist": object},
        2: ..
    }

    :param sample_no: number of samples to generate
    """
    results = {}

    for label, params in classes.items():
        dist = multivariate_normal(params["mean"], params["cov"])
        x = dist.rvs(size=sample_no)

        results[label] = {"samples": x, "dist": dist}

    return results

def covariance_contract() -> None:
    """
    Ensures that the covariance contract is respected (that the eigenvalues of the
    covariance matrices are within cov_eigen_bound).
    """
    for label, params in classes.items():
        if not all([(cov_eigen_bound[0] <= eigenv <= cov_eigen_bound[1]) \
                for eigenv in eig(params["cov"])[0]]):
            raise Exception('At least one covariance matrix has eigenvalues outside interval!')
        print(eig(params["cov"])[0])


def plot_samples(class_dist_samples: dict) -> None:
    """
    Plots the sample points generated by generate_and_sample.

    :param class_dist_samples: dictionary with class labels for keys and child dictionary containing
                               "samples" for values
    """
    fig = plt.figure(0)
    ax = fig.add_subplot(1, 1, 1, projection='3d')

    for class_label, data in class_dist_samples.items():
        samples = data["samples"]
        ax.set_xlabel('x0')
        ax.set_ylabel('x1')
        ax.set_zlabel('x2')
        img = ax.scatter(samples[:, 0], samples[:, 1], samples[:, 2],
                c=classes[class_label]["color"])

    plt.show()

covariance_contract()

def generate_sets() -> (dict, dict):
    """
    Generates training and testing sets for each size specified in
    train_set_sizes and test_set_sizes, respectively.

    For each type of set (train & test), a dictionary is created indexed
    by set size with value equal to the dict returned by generate_and_sample for
    that size.

                v----- training set of size 100 for each class (1, 2 etc.)
    i.e. tuple({100: {1: {"samples": [[..]], "dist": }, 2: {"samples: [[..]], "dist": }, ..},
                {10000: {1: {"samples: [..], "dict": ..}, 2: {"samples":...}}}
                 ^--- test set of size 10000 for each class (1, 2 etc.)

    :return: a tuple made up of training set dict and test set dict
    """
    # maps from set size to dict returned by generate_and_sample of that size
    train_sets = {}
    test_sets = {}

    for size in train_set_sizes:
        train_sets[size] = generate_and_sample(size)
        print(f'Generated training set of size {size}')

    for size in test_set_sizes:
        test_sets[size] = generate_and_sample(size)
        print(f'Generated test set of size {size}')

    plot_samples(train_sets[5000])

    return train_sets, test_sets

generate_sets()
